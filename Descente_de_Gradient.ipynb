{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "606d4fe7",
   "metadata": {},
   "source": [
    "# <center> Descente de Gradient </center>\n",
    "\n",
    "**Source :** LECUN Y., *Quand la machine apprend: la révolution des neurones artificiels et de l'apprentissage profond*, Odile Jacob, Paris, 2019, ISBN:9782738149312.\n",
    "\n",
    "**Objectif :** Trouver le minimum de la fonction de coût.\n",
    "\n",
    "Image de la vallée : La direction de la plus grande pente s’appelle le gradient de la fonction de coût. Le fond de la vallée est le minimum de la fonction de coût, et ses coordonnées sont les valeurs des paramètres qui minimisent le coût."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567c2baf",
   "metadata": {},
   "source": [
    "## Etapes de la Descente de Gradient :\n",
    "\n",
    "    \n",
    "1. Calculer le coût d’apprentissage pour la valeur actuelle du vecteur de paramètres (au point courant).\n",
    "\n",
    "\n",
    "2. Mesurer les pentes dans chacun des axes et collecter les pentes dans un vecteur de gradient **g**.\n",
    "\n",
    "\n",
    "3. Modifier le vecteur de paramètres dans la direction opposée au gradient. Pour ce faire, inverser les signes des composantes du gradient puis nous les multiplier par une constante **e** qu’on choisit, qui contrôle la taille du pas.\n",
    "\n",
    "\n",
    "4. Ajouter le vecteur résultant au vecteur de paramètres. Remplacer chaque composante du vecteur de paramètres par sa valeur courante moins la composante correspondante du vecteur de gradient multiplié par la taille du pas **e**.\n",
    "\n",
    "\n",
    "5. Cette taille du pas de gradient est importante : s’il est trop petit, on finira par trouver le minimum, mais cela prendra du temps, parce qu’à chaque pas, on avancera peu. Si le pas est trop grand, on risque de passer au-dessus du minimum et remonter de l’autre côté. Il faut donc que la constante **e** soit telle que les paramètres ne rebondissent pas d’un flanc de montagne au flanc opposé.\n",
    "\n",
    "\n",
    "6. Répéter les opérations jusqu’à tomber au fond de la vallée. Autrement dit, jusqu’à ce que la valeur de coût d’apprentissage cesse de diminuer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e4c343",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fonction de calcul de gradient par perturbation\n",
    "\n",
    "# X : tableau des entrées de l’ensemble de données\n",
    "x = [1, 2, 3, 4]\n",
    "\n",
    "# Y : tableau des sorties désirées\n",
    "y = [10, 20, 30, 40]\n",
    "\n",
    "# w : vecteur de paramètres\n",
    "w = [2, 2, 2, 2]\n",
    "\n",
    "# dw : perturbation\n",
    "\n",
    "\n",
    "def gradient(X,Y,w,dw) :\n",
    "\n",
    "    h = L(X,Y,w) # calcul du coût\n",
    "\n",
    "    wa = [0,0] # crée un vecteur wa\n",
    "\n",
    "    wa[0] = w[0] + dw # perturbation de la 1re coordonnée\n",
    "\n",
    "    wa[1] = w[1]\n",
    "\n",
    "    a = L(X,Y,wa) # calcul du coût après perturbation\n",
    "\n",
    "    wb = [0,0] # crée un vecteur wb\n",
    "\n",
    "    wb[0] = w[0]\n",
    "\n",
    "    wb[1] = w[1] + dw # perturbation de la 2e coordonnée\n",
    "\n",
    "    b = L(X,Y,wb) # calcul du coût après perturbation\n",
    "\n",
    "    g = [0,0] # crée un vecteur g\n",
    "\n",
    "    g[0] = (a−h)/dw # pente dans la 1re coordonnée\n",
    "\n",
    "    g[1] = (b−h)/dw # pente dans la 2e coordonnée\n",
    "\n",
    "    return g # retourne le vecteur de gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddabe4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# effectuer un pas de gradient\n",
    "\n",
    "# X : tableau des entrées de l’ensemble de données\n",
    "# Y : tableau des sorties désirées\n",
    "# w : vecteur de paramètres\n",
    "# e : pas de gradient\n",
    "# dw : perturbation\n",
    "\n",
    "def descend(X,Y,w,e,dw) :\n",
    "\n",
    "    g = gradient(X,Y,w,dw) # calcul du vecteur de gradient\n",
    "\n",
    "    w[0] = w[0] – e*g[0] # mise à jour de w[0]\n",
    "\n",
    "    w[1] = w[1] – e*g[1] # mise à jour de w[1]\n",
    "\n",
    "    return w # on renvoie le nouveau vecteur de paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207e38ac",
   "metadata": {},
   "source": [
    "Les étapes de l’apprentissage par descente de gradient consistent à :\n",
    "\n",
    "1. calculer le coût ;\n",
    "\n",
    "2. calculer le gradient ;\n",
    "\n",
    "3. mettre à jour les paramètres en soustrayant le gradient multiplié par une constante e, le pas de gradient.\n",
    "\n",
    "À force de répéter cette procédure, et à condition que le pas de gradient soit suffisamment petit, la procédure convergera vers le fond de la vallée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b799da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# procédure d’apprentissage\n",
    "\n",
    "# n : nombre d’itérations de la descente de gradient\n",
    "\n",
    "def learn(X,Y,w,e,dw,n) :\n",
    "\n",
    "    for i in range(n) : # répétons n fois\n",
    "\n",
    "        w = descend(X,Y,w,e,dw) # effectuons un pas\n",
    "\n",
    "        print(L(X,Y,w)) # imprimons la valeur du coût\n",
    "\n",
    "    return w # on renvoie le vecteur de poids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571d2431",
   "metadata": {},
   "source": [
    "Cette méthode de calcul avec des perturbations est peu efficace.\n",
    "\n",
    "Une méthode plus utile est la **méthode analytique de calcul du gradient**.\n",
    "\n",
    "**Elle revient à calculer des dérivées du coût dans la direction de chacun des axes sans perturbation**.\n",
    "\n",
    "La dérivée d'une fonction de plusieurs variables par rapport à une de ces variables, en considérant les autres variables comme des constants, s'appelle une **dérivée partielle**. C'est la pente de la fonction dans la direction de la variable considérée. \n",
    "\n",
    "Le vecteur formé par les dérivées partielles dans toutes les directions est le gradient.\n",
    "\n",
    "Il est donc possible de calculer le vecteur gradient à chacun des points sans utiliser de perturbation en calculant les dérivées partielles d'une fonction à l'aide d'une formule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5c90a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prenons un modèle linéaire tel que le perceptron décrit au chapitre précédent qui calcule le produit scalaire entre w et x :\n",
    "\n",
    "f(x,w) = dot(w,x)\n",
    "\n",
    "# et prenons une fonction de coût qui mesure le carré de l’erreur :\n",
    "\n",
    "C(x,y,w) = (y−f(x,w))**2\n",
    "\n",
    "# Le gradient sera simplement :\n",
    "\n",
    "dc_dw[0] = −2*(y−f(x,w))*x[0]\n",
    "\n",
    "dc_dw[1] = −2*(y−f(x,w))*x[1]\n",
    "\n",
    "…\n",
    "\n",
    "dc_dw[n–1] = −2*(y−f(x,w))*x[n–1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0279e7ee",
   "metadata": {},
   "source": [
    "## Le gradient stochastique\n",
    "\n",
    "Au lieu de calculer la moyenne du coût et de trouver le gradient de cette moyenne sur tous les exemples d’apprentissage pour faire un pas, on utilise les dérivées partielles pour calculer le gradient du coût pour un seul exemple et on effectue un pas dans la foulée.\n",
    "\n",
    "\n",
    "= gain de temps/calcul considérable\n",
    "\n",
    "\n",
    "Le système tire juste un exemple de manière aléatoire dans l’ensemble d’apprentissage, il calcule le gradient du coût pour cet exemple et il fait un pas de gradient. Ensuite, il pioche un autre exemple, il calcule le gradient du coût pour ce nouvel exemple et fait à nouveau un pas de gradient. On répète l’opération jusqu’à ce qu’on ne puisse plus descendre. La taille du pas doit diminuer au fur et à mesure qu’on se rapproche du fond de la vallée. En pratique, au lieu de prendre un seul exemple pour effectuer un pas, on fait la moyenne du gradient sur un petit groupe d’exemples qu’on appelle un « *mini-batch* ».\n",
    "\n",
    "À chaque pas, le gradient pointe dans une direction différente, ce qui amène le vecteur de paramètres à suivre une trajectoire erratique au cours de l’apprentissage. Mais bon an mal an, il se dirige vers le fond de la vallée. Plus surprenant : il y parvient même plus rapidement qu’en calculant le gradient sur l’ensemble d’apprentissage complet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b33059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# procédure d’apprentissage par gradient stochastique\n",
    "\n",
    "# n : nombre d’itérations de la descente de gradient\n",
    "\n",
    "def SGD(X,Y,w,e,n) :\n",
    "\n",
    "p = len(X) # nombre d’exemples d’apprentissage\n",
    "\n",
    "for i in range(n) : # répétons n fois\n",
    "\n",
    "    k = random.randrange(0,p) # tirage nombre aléatoire\n",
    "\n",
    "    g = gradC(X[k],Y[k],w) # calcul du gradient\n",
    "\n",
    "    for j in range(len(w)) : # boucle sur les paramètres\n",
    "\n",
    "        w[j]=w[j]−e*g[j] # mise à jour des paramètres\n",
    "\n",
    "    return w # on renvoie le vecteur de paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b83c9c8",
   "metadata": {},
   "source": [
    "## Problème minimal local/minimal global\n",
    "\n",
    "Problèmes récurrents pour les NN à 2 couches ou plus.\n",
    "\n",
    "Solution = fonction convexe (un seul minimum) mais les NN multicouche sont non-convexe par nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9422423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
